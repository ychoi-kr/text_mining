{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('2016_filtered_review_part.txt', encoding='utf-8') as f:\n",
    "    docs = [doc.strip().split('\\t\\t') for doc in f]\n",
    "    docs = [(doc[1], int(doc[2])) for doc in docs if len(doc) == 3]\n",
    "    # To read the second and third column info from each row\n",
    "    texts, scores = zip(*docs)\n",
    "    # 둘을 분리해서 별도의 list 변수로 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평점 정보를 이용해서 종속변수 레이블링 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_texts = []\n",
    "filtered_labels = []\n",
    "\n",
    "for text, score in zip(texts, scores):\n",
    "    if 4 < score < 8:\n",
    "        continue\n",
    "        \n",
    "    # 평점 기준으로 문서에 label을 부여\n",
    "    # 1 ~ 4 -> 부정, 0\n",
    "    # 8 ~ 10 -> 긍정, 1\n",
    "    filtered_texts.append(text)\n",
    "    filtered_labels.append(1 if score >= 8 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 영화평의 수: 19513\n",
      "긍정 영화평의 수: 17890\n",
      "긍정 영화평의 비율: 0.92\n"
     ]
    }
   ],
   "source": [
    "# 불균형 문제\n",
    "print('전체 영화평의 수: {}'.format(len(filtered_labels)))\n",
    "print('긍정 영화평의 수: {}'.format(sum(filtered_labels)))\n",
    "print('긍정 영화평의 비율: {0:.2f}'.format(sum(filtered_labels)/len(filtered_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To split the data into training and test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(filtered_texts, filtered_labels, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'영화 괜찮 재미있'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. L1 규제화 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tf_l1 = LogisticRegression(C=0.1, penalty='l1', solver='saga', max_iter=10000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 TF 정보 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "tf_vectorizer = CountVectorizer() \n",
    "tf_train_features = tf_vectorizer.fit_transform(train_texts) \n",
    "tf_test_features = tf_vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning time: 0.918 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "lr_tf_l1.fit(tf_train_features, train_labels) # 학습\n",
    "end = time.time()\n",
    "elapsed = end - start \n",
    "print('\\nLearning time: {0:.3f} seconds'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels_tf_l1 = lr_tf_l1.predict(tf_test_features) # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9369877049180327"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels, pred_labels_tf_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "긍정과 부정의 역할을 하는 단어 출력해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 사전 만들기\n",
    "words_dict = {}\n",
    "for word, index in tf_vectorizer.vocabulary_.items():\n",
    "    words_dict[index]=word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 단어 상위 30 개\n",
      "재밌 (1.523)\n",
      "재미있 (1.371)\n",
      "최고 (1.266)\n",
      "역시 (0.924)\n",
      "영상미 (0.768)\n",
      "도르마무 (0.662)\n",
      "아이 (0.640)\n",
      "다음 (0.584)\n",
      "추천 (0.517)\n",
      "영상 (0.478)\n",
      "마블 (0.431)\n",
      "스트레인 (0.349)\n",
      "연기 (0.329)\n",
      "약간 (0.317)\n",
      "닥터스 (0.235)\n",
      "기대 (0.232)\n",
      "효과 (0.213)\n",
      "멋지 (0.177)\n",
      "망토 (0.175)\n",
      "베네딕트 (0.157)\n",
      "베니 (0.157)\n",
      "아이맥스 (0.143)\n",
      "생각 (0.114)\n",
      "조금 (0.102)\n",
      "괜찮 (0.089)\n",
      "닌자 (0.079)\n",
      "독특 (0.074)\n",
      "거북이 (0.037)\n",
      "시각 (0.033)\n",
      "19금 (0.000)\n",
      "\n",
      "부정 단어 상위 30 개\n",
      "나오 (-0.271)\n",
      "이해 (-0.274)\n",
      "졸리 (-0.284)\n",
      "너무 (-0.335)\n",
      "영화 (-0.345)\n",
      "처음 (-0.363)\n",
      "기분 (-0.379)\n",
      "개연 (-0.435)\n",
      "진심 (-0.437)\n",
      "스토리 (-0.524)\n",
      "음악 (-0.525)\n",
      "노래 (-0.560)\n",
      "핵노잼 (-0.567)\n",
      "그냥 (-0.601)\n",
      "초딩 (-0.637)\n",
      "정신 (-0.662)\n",
      "손예진 (-0.692)\n",
      "내용 (-0.741)\n",
      "평점 (-0.814)\n",
      "유치 (-0.850)\n",
      "쓰레기 (-0.931)\n",
      "실망 (-0.970)\n",
      "감독 (-1.291)\n",
      "낭비 (-1.338)\n",
      "별로 (-1.364)\n",
      "짜증 (-1.411)\n",
      "알바 (-1.861)\n",
      "재미없 (-2.509)\n",
      "최악 (-2.946)\n",
      "노잼 (-3.038)\n"
     ]
    }
   ],
   "source": [
    "# Get coefficients of the model\n",
    "coefficients = lr_tf_l1.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# 학습에 사용된 각 단어마다의 coefficient (즉 weight) 값이 존재\n",
    "# coefficient값이 큰 순으로 정렬 'reverse=True'\n",
    "\n",
    "\n",
    "K=30\n",
    "# print top K positive words\n",
    "print(\"긍정 단어 상위 {} 개\".format(str(K)))\n",
    "for word_id, coef in sorted_coefficients[:K]:\n",
    "    print('{0:} ({1:.3f})'.format(words_dict[word_id], coef))\n",
    "# print top K negative words\n",
    "print(\"\\n부정 단어 상위 {} 개\".format(str(K)))\n",
    "for word_id, coef in sorted_coefficients[-K:]:\n",
    "    print('{0:} ({1:.3f})'.format(words_dict[word_id], coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 TF-IDF 정보 사용해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "tfidf_train_features = tfidf_vectorizer.fit_transform(train_texts) \n",
    "tfidf_test_features = tfidf_vectorizer.transform(test_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tfidf_l1 = LogisticRegression(C=0.1, penalty='l1', solver='saga', max_iter=10000) \n",
    "lr_tfidf_l1.fit(tfidf_train_features, train_labels) # 학습\n",
    "pred_labels_tfidf_l1 = lr_tfidf_l1.predict(tfidf_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9344262295081968"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels, pred_labels_tfidf_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "상위 긍, 부정 단어 출력해 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 단어 상위 30 개\n",
      "재밌 (3.786)\n",
      "재미있 (2.545)\n",
      "최고 (1.708)\n",
      "마블 (1.559)\n",
      "도르마무 (1.029)\n",
      "역시 (1.026)\n",
      "영상미 (0.636)\n",
      "아이 (0.326)\n",
      "기대 (0.262)\n",
      "영상 (0.167)\n",
      "19금 (0.000)\n",
      "1으 (0.000)\n",
      "2가 (0.000)\n",
      "2관 (0.000)\n",
      "2디 (0.000)\n",
      "2화 (0.000)\n",
      "3d (0.000)\n",
      "3디 (0.000)\n",
      "3베니마블 (0.000)\n",
      "4d (0.000)\n",
      "4디 (0.000)\n",
      "d강추 (0.000)\n",
      "oo노잼 (0.000)\n",
      "ㄱ저냥 (0.000)\n",
      "ㄹ혜 (0.000)\n",
      "ㅅ흡 (0.000)\n",
      "ㅈ노잼 (0.000)\n",
      "ㅈ루 (0.000)\n",
      "ㅋㅋ왤 (0.000)\n",
      "ㅋㅋ재밋게 (0.000)\n",
      "부정 단어 상위 30 개\n",
      "히트 (0.000)\n",
      "히트다히트 (0.000)\n",
      "히트작 (0.000)\n",
      "히피 (0.000)\n",
      "히헿 (0.000)\n",
      "히히 (0.000)\n",
      "히히히헤헤헤히힣 (0.000)\n",
      "힌트 (0.000)\n",
      "힐로 (0.000)\n",
      "힐링 (0.000)\n",
      "힘내 (0.000)\n",
      "힘들 (0.000)\n",
      "힘쓰 (0.000)\n",
      "힘없이 (0.000)\n",
      "힙합 (0.000)\n",
      "너무 (-0.007)\n",
      "짜증 (-0.217)\n",
      "음악 (-0.282)\n",
      "스토리 (-0.573)\n",
      "그냥 (-0.700)\n",
      "영화 (-1.035)\n",
      "내용 (-1.234)\n",
      "손예진 (-1.573)\n",
      "별로 (-2.301)\n",
      "평점 (-2.924)\n",
      "알바 (-3.396)\n",
      "노잼 (-3.700)\n",
      "감독 (-3.805)\n",
      "재미없 (-4.846)\n",
      "최악 (-6.287)\n"
     ]
    }
   ],
   "source": [
    "coefficients = lr_tfidf_l1.coef_.tolist()\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "\n",
    "K=30\n",
    "# print top K positive words\n",
    "print(\"긍정 단어 상위 {} 개\".format(str(K)))\n",
    "for word_id, coef in sorted_coefficients[:K]:\n",
    "    print('{0:} ({1:.3f})'.format(words_dict[word_id], coef))\n",
    "# print top K negative words\n",
    "print(\"부정 단어 상위 {} 개\".format(str(K)))\n",
    "for word_id, coef in sorted_coefficients[-K:]:\n",
    "    print('{0:} ({1:.3f})'.format(words_dict[word_id], coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 규제화 사용해 보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF 정보 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tf_l2 = LogisticRegression(C=0.1, penalty='l2', solver='saga', max_iter=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learning time: 0.498 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "lr_tf_l2.fit(tf_train_features, train_labels) # 학습\n",
    "end = time.time()\n",
    "elapsed = end - start \n",
    "print('\\nLearning time: {0:.3f} seconds'.format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels_tf_l2 = lr_tf_l2.predict(tf_test_features) # 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9369877049180327"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels, pred_labels_tf_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 단어 상위 30 개\n",
      "재밌 (1.447)\n",
      "재미있 (1.258)\n",
      "최고 (1.132)\n",
      "역시 (0.909)\n",
      "영상미 (0.765)\n",
      "아이 (0.746)\n",
      "도르마무 (0.733)\n",
      "다음 (0.723)\n",
      "추천 (0.695)\n",
      "약간 (0.671)\n",
      "망토 (0.574)\n",
      "영상 (0.560)\n",
      "독특 (0.558)\n",
      "아이맥스 (0.536)\n",
      "베니 (0.534)\n",
      "스트레인 (0.524)\n",
      "재밋 (0.503)\n",
      "멋지 (0.500)\n",
      "효과 (0.499)\n",
      "닥터스 (0.491)\n",
      "한국 (0.488)\n",
      "호강 (0.486)\n",
      "조금 (0.459)\n",
      "그리 (0.456)\n",
      "재미나 (0.446)\n",
      "마블 (0.444)\n",
      "연기 (0.443)\n",
      "시각 (0.439)\n",
      "아주 (0.423)\n",
      "만족 (0.415)\n",
      "\n",
      "부정 단어 상위 30 개\n",
      "비추 (-0.538)\n",
      "그냥 (-0.542)\n",
      "차라리 (-0.572)\n",
      "개연 (-0.577)\n",
      "스토리 (-0.579)\n",
      "노래 (-0.584)\n",
      "그나마 (-0.627)\n",
      "막장 (-0.641)\n",
      "보다 (-0.652)\n",
      "손예진 (-0.652)\n",
      "진심 (-0.659)\n",
      "짬뽕 (-0.667)\n",
      "졸리 (-0.710)\n",
      "정신 (-0.743)\n",
      "내용 (-0.749)\n",
      "개노잼 (-0.758)\n",
      "초딩 (-0.780)\n",
      "평점 (-0.791)\n",
      "핵노잼 (-0.825)\n",
      "쓰레기 (-0.860)\n",
      "유치 (-0.870)\n",
      "실망 (-0.931)\n",
      "짜증 (-1.009)\n",
      "낭비 (-1.040)\n",
      "감독 (-1.106)\n",
      "별로 (-1.294)\n",
      "알바 (-1.422)\n",
      "노잼 (-1.822)\n",
      "재미없 (-1.926)\n",
      "최악 (-1.933)\n"
     ]
    }
   ],
   "source": [
    "# Get coefficients of the model\n",
    "coefficients = lr_tf_l2.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# 학습에 사용된 각 단어마다의 coefficient (즉 weight) 값이 존재\n",
    "# coefficient값이 큰 순으로 정렬 'reverse=True'\n",
    "\n",
    "\n",
    "K=30\n",
    "# print top K positive words\n",
    "print(\"긍정 단어 상위 {} 개\".format(str(K)))\n",
    "for word_id, coef in sorted_coefficients[:K]:\n",
    "    print('{0:} ({1:.3f})'.format(words_dict[word_id], coef))\n",
    "# print top K negative words\n",
    "print(\"\\n부정 단어 상위 {} 개\".format(str(K)))\n",
    "for word_id, coef in sorted_coefficients[-K:]:\n",
    "    print('{0:} ({1:.3f})'.format(words_dict[word_id], coef))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF 정보 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_tfidf_l2 = LogisticRegression(C=0.1, penalty='l2', solver='saga', max_iter=10000) \n",
    "lr_tfidf_l2.fit(tfidf_train_features, train_labels) # 학습\n",
    "pred_labels_tfidf_l2 = lr_tfidf_l2.predict(tfidf_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.930327868852459"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_labels, pred_labels_tfidf_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정 단어 상위 30 개\n",
      "재밌 (2.306)\n",
      "재미있 (1.680)\n",
      "마블 (1.265)\n",
      "최고 (1.254)\n",
      "역시 (1.077)\n",
      "영상미 (0.912)\n",
      "도르마무 (0.859)\n",
      "아이 (0.854)\n",
      "영상 (0.710)\n",
      "추천 (0.671)\n",
      "다음 (0.651)\n",
      "기대 (0.650)\n",
      "아이맥스 (0.496)\n",
      "망토 (0.476)\n",
      "베네딕트 (0.470)\n",
      "멋지 (0.457)\n",
      "약간 (0.451)\n",
      "닥터스 (0.443)\n",
      "베니 (0.443)\n",
      "쿠키 (0.436)\n",
      "볼거리 (0.432)\n",
      "효과 (0.428)\n",
      "트레인 (0.423)\n",
      "스트레인 (0.416)\n",
      "거래 (0.405)\n",
      "닥터 (0.394)\n",
      "시각 (0.380)\n",
      "호강 (0.379)\n",
      "완전 (0.377)\n",
      "재밋 (0.370)\n",
      "\n",
      "부정 단어 상위 30 개\n",
      "기분 (-0.540)\n",
      "비밀 (-0.550)\n",
      "초딩 (-0.589)\n",
      "수준 (-0.591)\n",
      "개노잼 (-0.591)\n",
      "개연 (-0.602)\n",
      "이해 (-0.612)\n",
      "정신 (-0.626)\n",
      "노래 (-0.646)\n",
      "진심 (-0.668)\n",
      "보다 (-0.687)\n",
      "실망 (-0.717)\n",
      "유치 (-0.731)\n",
      "핵노잼 (-0.758)\n",
      "그냥 (-0.799)\n",
      "스토리 (-0.813)\n",
      "낭비 (-0.817)\n",
      "쓰레기 (-0.843)\n",
      "음악 (-0.864)\n",
      "짜증 (-0.926)\n",
      "영화 (-0.973)\n",
      "내용 (-1.071)\n",
      "손예진 (-1.232)\n",
      "알바 (-1.533)\n",
      "별로 (-1.551)\n",
      "감독 (-1.632)\n",
      "노잼 (-1.637)\n",
      "평점 (-1.822)\n",
      "최악 (-2.245)\n",
      "재미없 (-2.273)\n"
     ]
    }
   ],
   "source": [
    "# Get coefficients of the model\n",
    "coefficients = lr_tfidf_l2.coef_.tolist()\n",
    "\n",
    "sorted_coefficients = sorted(enumerate(coefficients[0]), key=lambda x:x[1], reverse=True)\n",
    "# 학습에 사용된 각 단어마다의 coefficient (즉 weight) 값이 존재\n",
    "# coefficient값이 큰 순으로 정렬 'reverse=True'\n",
    "\n",
    "\n",
    "K=30\n",
    "# print top K positive words\n",
    "print(\"긍정 단어 상위 {} 개\".format(str(K)))\n",
    "for word_id, coef in sorted_coefficients[:K]:\n",
    "    print('{0:} ({1:.3f})'.format(words_dict[word_id], coef))\n",
    "# print top K negative words\n",
    "print(\"\\n부정 단어 상위 {} 개\".format(str(K)))\n",
    "for word_id, coef in sorted_coefficients[-K:]:\n",
    "    print('{0:} ({1:.3f})'.format(words_dict[word_id], coef))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
